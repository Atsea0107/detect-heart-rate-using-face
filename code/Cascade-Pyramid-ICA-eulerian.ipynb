{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import scipy.fftpack as fftpack\n",
    "from scipy.signal import detrend \n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.decomposition import FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_laplacian_pyramid(img, levels):\n",
    "    gaussian_pyramid = cv2.pyrDown(img)\n",
    "\n",
    "    upsampled = cv2.pyrUp(gaussian_pyramid)\n",
    "    (height, width, depth) = upsampled.shape\n",
    "    gaussian_pyramid = cv2.resize(gaussian_pyramid, (height, width))\n",
    "\n",
    "    return cv2.subtract(gaussian_pyramid, upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(path):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    video_frames = []\n",
    "    check = True\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        channel_avg = list(img.mean(axis=(0, 1)))\n",
    "\n",
    "        # Detect face\n",
    "        if check:\n",
    "            face_detector = faceCascade.detectMultiScale(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), 1.3, 5)\n",
    "            if len(face_detector) > 0:\n",
    "                print(face_detector)\n",
    "                (x, y, w, h) = face_detector[0]\n",
    "                check = False\n",
    "        \n",
    "        if not check:\n",
    "            img = cv2.resize(img[y:y + h, x:x + w], (500, 500)) * (1. / 255)\n",
    "            video_frames.append(build_laplacian_pyramid(img, 3))\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    return np.array(video_frames), fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3) :\n",
    "    '''simple moving average, n=kernel size'''\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "def preprocess(arr):\n",
    "    '''arg = 1D array - smooth, remove trend, normalize array'''\n",
    "    ma = moving_average(arr, 4) #smooth raw color signals \n",
    "    detrended = detrend(ma)     #scipy detrend \n",
    "    normalized = (detrended-np.mean(detrended))/np.std(detrended)\n",
    "    return normalized \n",
    "\n",
    "def ICA(arr):\n",
    "    ica = FastICA(n_components=3, max_iter=1000)\n",
    "    ica_transformed = ica.fit_transform(arr)\n",
    "    return ica_transformed\n",
    "\n",
    "def full_process(mixed_signal): \n",
    "    '''full signal processing pipeline'''\n",
    "    mixed_signal = np.array(mixed_signal) #prep (len, color)\n",
    "    normalized = np.apply_along_axis(preprocess, 0, mixed_signal) #detrend and normalize \n",
    "    ICA_transformed = ICA(normalized) #ICA \n",
    "    return ICA_transformed\n",
    "\n",
    "def get_pulse_signal(frames):\n",
    "    pulse_signals = []\n",
    "    for frame in frames:\n",
    "        pulse_signals.append(list(frame.mean(axis=(0, 1))))\n",
    "        # lap_video.append(sum(channel_avg) / len(channel_avg))\n",
    "    \n",
    "    return pulse_signals\n",
    "\n",
    "def bandpass(x, y, low_pass=3, high_pass=0):\n",
    "    '''bandpass filter for fourier'''\n",
    "    y = y[np.where((x<low_pass) & (x>high_pass))]\n",
    "    x = x[np.where((x<low_pass) & (x>high_pass))]\n",
    "    return x, y\n",
    "\n",
    "def fourier_transform(x, y, channel=1):\n",
    "    '''perform fourier transform'''\n",
    "    y = y[:, channel] #pick ICA color channel to process on \n",
    "    \n",
    "    N = len(y)                            # Number of data points\n",
    "    T = 1./fps                            # delta between frames (s)\n",
    "    yf = fftpack.fft(y)                           # perform scipy fourier \n",
    "    xf = np.linspace(0.0, 1/(T*2), N//2)  # replot complex data over freq domain\n",
    "\n",
    "    y_transform = 2.0/N * np.abs(yf[0:N//2])\n",
    "    freq_spec, power_spec = bandpass(xf, y_transform, 4., 0.8)\n",
    "    bpm = freq_spec*60    #convert Hz to bpm \n",
    "    \n",
    "    heart_rate = bpm[np.argmax(power_spec)] #highest peak == HR\n",
    "    \n",
    "    return heart_rate, bpm, power_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt0.xml\")\n",
    "\n",
    "freq_min = 1\n",
    "freq_max = 1.8\n",
    "\n",
    "base = '../data'\n",
    "# file_name : fileNumber_tureHR.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(base):\n",
    "    video, fps = read_video(os.path.join(base, file))\n",
    "\n",
    "    singals = get_pulse_signal(video)\n",
    "    y_in = full_process(singals)\n",
    "    heart_rate, bpm, power_spec = fourier_transform(fps, y_in)\n",
    "\n",
    "    file_name = file.split('.')[0]\n",
    "    print(f\"{file_name.split('_')[0]}: {file_name.split('_')[1]} {heart_rate},\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mixed ica and eulerian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_filter_ica(y, fps, freq_min, freq_max):\n",
    "    fft = fftpack.fft(y)\n",
    "    frequencies = fftpack.fftfreq(y.shape[0], d=1.0 / fps)\n",
    "    \n",
    "    bound_low = (np.abs(frequencies - freq_min)).argmin()\n",
    "    bound_high = (np.abs(frequencies - freq_max)).argmin()\n",
    "    fft[:bound_low] = 0\n",
    "    fft[bound_high:-bound_high] = 0\n",
    "    fft[-bound_low:] = 0\n",
    "    \n",
    "    iff = fftpack.ifft(fft, axis=0)\n",
    "\n",
    "    return fft, frequencies\n",
    "\n",
    "def find_heart_rate(fft, freqs, freq_min, freq_max):\n",
    "    fft_maximums = []\n",
    "\n",
    "    for i in range(fft.shape[0]):\n",
    "        if freq_min <= freqs[i] <= freq_max:\n",
    "            fftMap = abs(fft[i])\n",
    "            fft_maximums.append(fftMap.max())\n",
    "        else:\n",
    "            fft_maximums.append(0)\n",
    "\n",
    "    peaks, properties = signal.find_peaks(fft_maximums)\n",
    "    max_peak = -1\n",
    "    max_freq = 0\n",
    "\n",
    "    for peak in peaks:\n",
    "        if fft_maximums[peak] > max_freq:\n",
    "            max_freq = fft_maximums[peak]\n",
    "            max_peak = peak\n",
    "\n",
    "    return freqs[max_peak] * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(base):\n",
    "    video, fps = read_video(os.path.join(base, file))\n",
    "\n",
    "    singals = get_pulse_signal(video)\n",
    "    y_in = full_process(singals)\n",
    "    \n",
    "    fft, frequencies = fft_filter_ica(y_in, fps, freq_min, freq_max)\n",
    "    heart_rate = find_heart_rate(fft, frequencies, freq_min, freq_max)\n",
    "\n",
    "    file_name = file.split('.')[0]\n",
    "    print(f\"{file_name.split('_')[0]}: {file_name.split('_')[1]} {heart_rate},\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
